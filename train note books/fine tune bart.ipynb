{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to finetune BART model\n",
    "This script generates a fine tuned BART model from the fine tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from BART_utilities import *\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus = pd.read_json('../../../dataset/legal_summarization/airbus_helicopters_train_set.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus_test =  pd.read_json('test_set.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_V1 = pd.read_json('all_v1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus = airbus.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus_test = airbus_test.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_V1 = all_V1.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus = airbus.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus_test = airbus_test.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_V1 = all_V1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_V1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus_train = airbus[['original_text', 'reference_summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus_test_test = airbus_test[['original_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_v1 = all_V1[['original_text', 'reference_summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BartConfig\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large', add_prefix_space=True)\n",
    "\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special tokens if required\n",
    "\n",
    "new_tokens = ['<F>', '<RLC>', '<A>', '<S>', '<P>', '<R>', '<RPC>']\n",
    "\n",
    "special_tokens_dict = {'additional_special_tokens': new_tokens}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "bart_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = SummaryDataModule(tokenizer, airbus_train, batch_size = 1)\n",
    "model = LitModel(learning_rate = 2e-5, tokenizer = tokenizer, model = bart_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = summary_data.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## enregistre le test_data\n",
    "test_data.to_csv('test_data_allV1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data.setup(stage=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = summary_data.train_dataloader()\n",
    "val_dataloader = summary_data.val_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(save_dir='logs/all_v2', version=1, name=\"lightning_logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt_path=None\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=4,\n",
    "    min_epochs=0,\n",
    "    precision='bf16-mixed',\n",
    "    num_sanity_val_steps=2,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | BartForConditionalGeneration | 406 M \n",
      "-------------------------------------------------------\n",
      "406 M     Trainable params\n",
      "0         Non-trainable params\n",
      "406 M     Total params\n",
      "1,625.194 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/330 [00:19<?, ?it/s]s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  49%|████▉     | 162/330 [1:12:33<1:15:14,  0.04it/s, v_num=1]    "
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "trainer.save_checkpoint(\"outputtrainedallV1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = LitModel.load_from_checkpoint(\"./logs/lightning_logs/version_1/checkpoints/epoch=0-step=100.ckpt\", learning_rate=2e-5, tokenizer=tokenizer, model=bart_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in airbus_test.iterrows():\n",
    "    inputs = tokenizer(row['original_text'], return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    generated_text = loaded_model.generate_text(inputs, eval_beams=5)\n",
    "    print(generated_text[0])\n",
    "    airbus_test.at[i, 'generated_summary'] = generated_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_generated = test_data[['generated_summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_test = airbus.merge(test_data_generated, left_index=True, right_index=True, how='left')\n",
    "merge_test = merge_test.dropna()\n",
    "merge_test.set_index('index', inplace=True)\n",
    "merge_test = merge_test.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbus_test.set_index('index', inplace=True)\n",
    "airbus_test = airbus_test.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = airbus_test.to_dict()\n",
    "\n",
    "# Créer une structure de données appropriée pour le JSON de sortie\n",
    "json_data_original = {}\n",
    "for key, value in data_dict.items():\n",
    "    print(key, value)\n",
    "    json_data_original[key] = {\n",
    "        'uid': value['uid'],\n",
    "        'original_text': value['original_text'],\n",
    "        'reference_summary': value['original_text']\n",
    "    }\n",
    "    \n",
    "json_data_generated = {}\n",
    "for key, value in data_dict.items():\n",
    "    json_data_generated[key] = {\n",
    "        'uid': value['uid'],\n",
    "        'generated_summary': value['generated_summary']\n",
    "    }\n",
    "    \n",
    "# Écrire le dictionnaire dans un fichier JSON\n",
    "with open('jsonoriginal.json', 'w') as json_file:\n",
    "    json.dump(json_data_original, json_file)\n",
    "\n",
    "# Écrire le dictionnaire dans un fichier JSON\n",
    "with open('jsongenerated.json', 'w') as json_file:\n",
    "    json.dump(json_data_generated, json_file)\n",
    "    \n",
    "## python evaluate.py -r 'jsonoriginal.json' -g 'jsongenerated.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## propres métriques de scores\n",
    "def scores(test):\n",
    "    from rouge import Rouge\n",
    "    from sentence_transformers import SentenceTransformer, util\n",
    "    from bert_score import score\n",
    "\n",
    "\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    rouge = Rouge()\n",
    "\n",
    "    # Définir une fonction pour calculer les scores ROUGE pour chaque ligne\n",
    "    compute_rouge_scores = lambda row: rouge.get_scores(row['target'], row['source'], avg=True)\n",
    "    embeggings_target = lambda row: model.encode(row['target'], convert_to_tensor=True)\n",
    "    embeggings_source = lambda row: model.encode(row['source'], convert_to_tensor=True)\n",
    "    cosin_score = lambda row: util.cos_sim(row['embeggings_target'], row['embeggings_source'])\n",
    "    compute_bert_score = lambda row: score([row['target']], [row['source']], lang='fr')\n",
    "\n",
    "\n",
    "    # Appliquer la fonction lambda à chaque ligne et stocker les scores ROUGE dans une nouvelle colonne 'scores'\n",
    "    test['scores'] = test.apply(compute_rouge_scores, axis=1)\n",
    "    test['embeggings_target'] = test.apply(embeggings_target, axis=1)\n",
    "    test['embeggings_source'] = test.apply(embeggings_source, axis=1)\n",
    "    test['cosin_score'] = test.apply(cosin_score, axis=1)\n",
    "    test['bert_score'] = test.apply(compute_bert_score, axis=1)\n",
    "    test['P'] = test['bert_score'].apply(lambda x: x[0].item())\n",
    "    test['R'] = test['bert_score'].apply(lambda x: x[1].item())\n",
    "    test['F1'] = test['bert_score'].apply(lambda x: x[2].item())\n",
    "\n",
    "    # Définir une fonction pour extraire les valeurs ROUGE-1, ROUGE-2 et ROUGE-L pour chaque ligne\n",
    "    extract_rouge_scores = lambda row: (\n",
    "        row['rouge-1']['r'], row['rouge-1']['f'], row['rouge-1']['p'],\n",
    "        row['rouge-2']['r'], row['rouge-2']['f'], row['rouge-2']['p'],\n",
    "        row['rouge-l']['r'], row['rouge-l']['f'], row['rouge-l']['p']\n",
    "    )\n",
    "\n",
    "    # Appliquer la fonction lambda à chaque ligne et stocker les scores ROUGE dans de nouvelles colonnes\n",
    "    test[['rouge-1_r', 'rouge-1_f', 'rouge-1', 'rouge-2_r', 'rouge-2_f', 'rouge-2', 'rouge-l_r', 'rouge-l_f', 'rouge-l']] = test['scores'].apply(extract_rouge_scores).apply(pd.Series)\n",
    "\n",
    "    extract_item = lambda x: x.item()\n",
    "    test['cosin_score_item'] = test['cosin_score'].apply(extract_item)\n",
    "    \n",
    "    score_result = {\n",
    "    'rouge1': test_data['rouge-1'].mean(),\n",
    "    'rouge2':test_data['rouge-2'].mean(),\n",
    "    'rougel':test_data['rouge-l'].mean(),\n",
    "    'bertP' : test_data['P'].mean(),\n",
    "    'bertR' : test_data['R'].mean(),\n",
    "    'bertF1' : test_data['F1'].mean(),\n",
    "    'cosinscore' : test_data['cosin_score_item'].mean()\n",
    "    \n",
    "    }\n",
    "    \n",
    "    return score_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer\\u2019s orders are confirmed by the Seller in writing. The delivery schedule shall become effective upon receipt by the Customer of the Confirmation.\n",
    "\n",
    "Customer\\u2019s Orders shall be confirmed by the Seller in writing. The Contract shall become binding upon receipt by the Customer of the Seller\\u2019s Order Confirmation and the delivery schedule shall become effective upon receipt by the Seller of the down-payment when relevant (as mentioned under article 6.2) and subject to compliance by the Customer to article 4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Copying and/or reproducing, transmission to a third party of the Products or Services or technical information or Technical Data or training manuals without the Seller\\u2019s written express approval is strictly forbidden.\n",
    "\n",
    "Customer\\u2019s Orders shall be confirmed by the Seller in writing. The Contract shall become binding upon receipt by the Customer of the Seller\\u2019s Order Confirmation and the delivery schedule shall become effective upon receipt by the Seller of the down-payment when relevant (as mentioned under article 6.2) and subject to compliance by the Customer to article 4.1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
